{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008592,
     "end_time": "2020-12-20T23:05:17.391042",
     "exception": false,
     "start_time": "2020-12-20T23:05:17.382450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is an example of one of the many things you can do with this dataset. Here we will make a simple program to predict the emotion a person is feeling based on their message. We will start by importing the neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-20T23:05:17.414488Z",
     "iopub.status.busy": "2020-12-20T23:05:17.413608Z",
     "iopub.status.idle": "2020-12-20T23:05:18.840181Z",
     "shell.execute_reply": "2020-12-20T23:05:18.840766Z"
    },
    "papermill": {
     "duration": 1.440495,
     "end_time": "2020-12-20T23:05:18.840942",
     "exception": false,
     "start_time": "2020-12-20T23:05:17.400447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import numpy for linear algebra purposes\n",
    "import numpy as np\n",
    "#Import pandas to read the file\n",
    "import pandas as pd\n",
    "#Import a function to split our data for evaluation purposes\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Import neccessary functions to process the input message\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "#For this model, we will be using KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007099,
     "end_time": "2020-12-20T23:05:18.856837",
     "exception": false,
     "start_time": "2020-12-20T23:05:18.849738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next up, we have to process our inputs to create an X and y for our model to learn from. We will not have to worry about vectorizing our inputs, as the pipeline will do that for us. We will also split our data using train_test_split so we can evaluate how well our model preforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-20T23:05:18.884148Z",
     "iopub.status.busy": "2020-12-20T23:05:18.883418Z",
     "iopub.status.idle": "2020-12-20T23:05:19.574744Z",
     "shell.execute_reply": "2020-12-20T23:05:19.575296Z"
    },
    "papermill": {
     "duration": 0.711363,
     "end_time": "2020-12-20T23:05:19.575478",
     "exception": false,
     "start_time": "2020-12-20T23:05:18.864115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read the csv file\n",
    "df = pd.read_csv('topical_chat.csv')\n",
    "#X will be our message, and y will be the emotion\n",
    "X = df['message']\n",
    "y = df['sentiment']\n",
    "#Split our data for evaluation purposes, with our text size as 30% of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007308,
     "end_time": "2020-12-20T23:05:19.590482",
     "exception": false,
     "start_time": "2020-12-20T23:05:19.583174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, it is time to actually make the model. Here we can use a Pipeline which vectorizes the input, transforms it, and then applies the KNeighborsClasisifer to it. The reason we are using KNeighborsClassifier is because it is much faster than other algorithms, and we will use 1 neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T23:05:19.624879Z",
     "iopub.status.busy": "2020-12-20T23:05:19.619688Z",
     "iopub.status.idle": "2020-12-20T23:05:24.175631Z",
     "shell.execute_reply": "2020-12-20T23:05:24.175038Z"
    },
    "papermill": {
     "duration": 4.577595,
     "end_time": "2020-12-20T23:05:24.175741",
     "exception": false,
     "start_time": "2020-12-20T23:05:19.598146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfid', TfidfTransformer()),\n",
       "                ('algorithm', KNeighborsClassifier(n_neighbors=1))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will create our model to vectorize the text to be intepreted by KNeighborsClassifier\n",
    "model = Pipeline([\n",
    "    (\"vect\",CountVectorizer()),\n",
    "    (\"tfid\",TfidfTransformer()),\n",
    "    (\"algorithm\",KNeighborsClassifier(1))\n",
    "])\n",
    "#We will fit our pipeline to X_train and y_train to test it out\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007617,
     "end_time": "2020-12-20T23:05:24.191776",
     "exception": false,
     "start_time": "2020-12-20T23:05:24.184159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, it is time for the evaluation of the model. Before finding out the actual score of the model, we will create a function that can use the model to predict results, as we want to toy around with what we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T23:05:24.215406Z",
     "iopub.status.busy": "2020-12-20T23:05:24.214679Z",
     "iopub.status.idle": "2020-12-20T23:05:24.363002Z",
     "shell.execute_reply": "2020-12-20T23:05:24.362409Z"
    },
    "papermill": {
     "duration": 0.163309,
     "end_time": "2020-12-20T23:05:24.363121",
     "exception": false,
     "start_time": "2020-12-20T23:05:24.199812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Happy\n",
      " Happy\n",
      " Happy\n"
     ]
    }
   ],
   "source": [
    "#This function uses our model to predict based on text \n",
    "def predict_emotion(text):\n",
    "    return model.predict([text])[0]\n",
    "\n",
    "#Here, we are testing out the model and it's responses\n",
    "print(predict_emotion(\"why my payment not happenning, system is damp fool, my 25 taken\"))\n",
    "print(predict_emotion(\"You disguist me you horrible creature\"))\n",
    "print(predict_emotion(\"Please don't hurt me, I feel scared by you\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008492,
     "end_time": "2020-12-20T23:05:24.380447",
     "exception": false,
     "start_time": "2020-12-20T23:05:24.371955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we've toyed around with it, it's time to actually evaluate how good our model is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T23:05:24.453031Z",
     "iopub.status.busy": "2020-12-20T23:05:24.411112Z",
     "iopub.status.idle": "2020-12-20T23:10:17.296749Z",
     "shell.execute_reply": "2020-12-20T23:10:17.297435Z"
    },
    "papermill": {
     "duration": 292.908567,
     "end_time": "2020-12-20T23:10:17.297607",
     "exception": false,
     "start_time": "2020-12-20T23:05:24.389040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 33%\n"
     ]
    }
   ],
   "source": [
    "#Convert our score to a string version of an integer from 1-100\n",
    "score = model.score(X_test, y_test) * 100\n",
    "score = str(int(score))\n",
    "#Display the score \n",
    "print(\"Model accuracy: \" + score + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008662,
     "end_time": "2020-12-20T23:10:17.315206",
     "exception": false,
     "start_time": "2020-12-20T23:10:17.306544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are many ways that our model could be improved. The most obvious one is cleaning the text, by lowercasing it all along with deleting certain puncuation. You could also make a neural network use pretrained embeddings to further the accuracy. I will leave that for other people to experiment with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 305.294579,
   "end_time": "2020-12-20T23:10:17.433090",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-20T23:05:12.138511",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
